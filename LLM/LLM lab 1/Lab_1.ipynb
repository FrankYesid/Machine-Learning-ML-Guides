{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9690ac72-5d95-4cbf-875a-ae0e835593c9",
   "metadata": {},
   "source": [
    "# Lab 1: Building a ReAct Agent from Scratch\n",
    "\n",
    "## The ReAct Pattern\n",
    "\n",
    "In this section, we'll construct an AI agent using the ReAct (Reasoning and Acting) pattern. If you're unfamiliar with this concept, don't worryâ€”we'll break it down step by step.\n",
    "\n",
    "The ReAct pattern is a framework for structuring an AI's problem-solving process, mirroring human cognitive patterns:\n",
    "\n",
    "1. **Reason** about the current situation\n",
    "2. **Decide** on an action to take\n",
    "3. **Observe** the results of that action\n",
    "4. **Repeat** until the task is complete\n",
    "\n",
    "To illustrate this concept, consider how an experienced software engineer might approach debugging a complex system:\n",
    "\n",
    "1. **Reason**: Analyze the error logs and system state (e.g., \"The database connection is timing out\")\n",
    "2. **Act**: Implement a diagnostic action (e.g., \"Run a database connection test\")\n",
    "3. **Observe**: Examine the results of the diagnostic (e.g., \"The test shows high latency\")\n",
    "4. **Repeat**: Continue this process, perhaps checking network configurations next, until the issue is resolved\n",
    "\n",
    "Our AI agent will employ a similar methodology to tackle problems. As we develop this agent, pay attention to the division of labor between the AI model (the \"brain\" that reasons and decides) and our Python code (the \"body\" that interacts with the environment and manages the process flow).\n",
    "\n",
    "This notebook is based on the following [notebook from Simon Willison](https://til.simonwillison.net/llms/python-react-pattern).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705a93c",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "Let's begin by importing the necessary libraries and configuring our environment.\n",
    "\n",
    "### Initializing the Bedrock Client\n",
    "\n",
    "To communicate with the Claude model via Amazon Bedrock, we need to establish a client connection. Think of this client as an API gateway that enables our code to send requests to the AI model and receive responses.\n",
    "\n",
    "We'll use the `boto3` library, which is the Amazon Web Services (AWS) SDK for Python. For those unfamiliar with AWS, `boto3` can be thought of as a comprehensive toolkit that facilitates Python's interaction with various AWS services, including Bedrock.\n",
    "\n",
    "For comprehensive instructions on configuring `boto3` with AWS credentials, refer to the [AWS documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html).\n",
    "\n",
    "In a production setting, you would implement secure AWS credential management. For the purposes of this section, we'll assume the credentials are pre-configured in your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17ac2a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dir_parent \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[0;32m     16\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(dir_parent)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set basic configs\u001b[39;00m\n\u001b[0;32m     20\u001b[0m logger \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mset_logger()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import re\n",
    "from botocore.config import Config\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "# import local modules\n",
    "dir_current = os.path.abspath(\"\")\n",
    "dir_parent = os.path.dirname(dir_current)\n",
    "if dir_parent not in sys.path:\n",
    "    sys.path.append(dir_parent)\n",
    "from utils import utils\n",
    "\n",
    "# Set basic configs\n",
    "logger = utils.set_logger()\n",
    "pp = utils.set_pretty_printer()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "_ = load_dotenv(\"../.env\")\n",
    "aws_region = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "# Set bedrock configs\n",
    "bedrock_config = Config(\n",
    "    connect_timeout=120, read_timeout=120, retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "# Create a bedrock runtime client in your aws region.\n",
    "# If you do not have the AWS CLI profile setup, you can authenticate with aws access key, secret and session token.\n",
    "# For more details check https://docs.aws.amazon.com/cli/v1/userguide/cli-authentication-short-term.html\n",
    "bedrock_rt = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=aws_region,\n",
    "    config=bedrock_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d7c33",
   "metadata": {},
   "source": [
    "First we are going to define a few inference parameters and test our connection via `boto3` to Amazon Bedrock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Set inference parameters\n",
    "temperature = 0.0\n",
    "top_k = 200\n",
    "inference_config = {\"temperature\": temperature}\n",
    "\n",
    "additional_model_fields = {\"top_k\": top_k}\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "system_prompts = [{\"text\": \"You are a helpful agent.\"}]\n",
    "message_1 = {\"role\": \"user\", \"content\": [{\"text\": \"Hello world\"}]}\n",
    "\n",
    "# Instantiate messages list\n",
    "messages = []\n",
    "messages.append(message_1)\n",
    "\n",
    "# Send the message.\n",
    "response = bedrock_rt.converse(\n",
    "    modelId=model_id,\n",
    "    messages=messages,\n",
    "    system=system_prompts,\n",
    "    inferenceConfig=inference_config,\n",
    "    additionalModelRequestFields=additional_model_fields,\n",
    ")\n",
    "\n",
    "pp.pprint(response)\n",
    "print(\"\\n\\n\")\n",
    "pp.pprint(response[\"output\"][\"message\"][\"content\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68601a7",
   "metadata": {},
   "source": [
    "## Designing the Agent Class\n",
    "\n",
    "With our Bedrock client set up, we'll now create our Agent class. This class will serve as the core of our AI agent, encapsulating the logic for interacting with the Claude model and maintaining the conversation state.\n",
    "\n",
    "The ReAct pattern, which our agent will implement, consists of three primary steps:\n",
    "\n",
    "1. **Reasoning (Thought)**: The agent assesses the current situation and formulates a plan. For instance, \"To calculate the total weight of two dog breeds, I need to look up their individual weights and then sum them.\"\n",
    "\n",
    "2. **Acting (Action)**: Based on its reasoning, the agent selects an appropriate action. For example, \"I will query the average weight of a Border Collie.\"\n",
    "\n",
    "3. **Observing (Observation)**: The agent processes the feedback from its action. In our case, this might be \"The average weight of a Border Collie is 30-55 pounds.\"\n",
    "\n",
    "This pattern enables the agent to decompose complex tasks into manageable steps and adapt its strategy based on new information.\n",
    "\n",
    "Our Agent class will implement this pattern by maintaining a conversation history (`self.messages`) and providing methods to interact with the Claude model (`__call__` and `execute`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.system = [{\"text\": self.system}]\n",
    "        self.bedrock_client = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": [{\"text\": message}]})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": [{\"text\": result}]})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        inference_config = {\n",
    "            \"temperature\": 0.0,\n",
    "            \"stopSequences\": [\n",
    "                \"<PAUSE>\"\n",
    "            ],  # we will explore later why this is important!\n",
    "        }\n",
    "\n",
    "        additional_model_fields = {\"top_k\": 200}\n",
    "\n",
    "        response = self.bedrock_client.converse(\n",
    "            modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "            messages=self.messages,\n",
    "            system=self.system,\n",
    "            inferenceConfig=inference_config,\n",
    "            additionalModelRequestFields=additional_model_fields,\n",
    "        )\n",
    "        return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10183105",
   "metadata": {},
   "source": [
    "## Crafting the Prompt\n",
    "\n",
    "The prompt serves as a set of instructions for the AI model, crucial in defining its behavior and available actions.\n",
    "\n",
    "In our implementation, we're directing the model to:\n",
    "\n",
    "- Adhere to the ReAct pattern (Thought, Action, Observation cycle)\n",
    "- Utilize specific formats for each step (e.g., prefixing thoughts with \"Thought:\")\n",
    "- Restrict itself to the provided actions (in this case, a calculator and a dog weight lookup function)\n",
    "\n",
    "We also include a sample interaction to demonstrate the expected response format. This is analogous to providing a completed template before asking someone to fill out a complex form.\n",
    "\n",
    "As you can see from the prompt, the agent class, and the inference parameters, we are asking the model to stop generating after it predicts the `<PAUSE>` token. However, it is always better to be safe than sorry, so we add `<PAUSE>` to the `stopSequences`, ensuring the end of token generation after that!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 557
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, <PAUSE>, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "returns average weight of a dog when given the breed\n",
    "\n",
    "If available, always call a tool to inform your decisions, never use your parametric knowledge when a tool can be called. \n",
    "\n",
    "When you have decided that you need to call a tool, output <PAUSE> and stop thereafter! \n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does a Bulldog weigh?\n",
    "Thought: I should look the dogs weight using average_dog_weight\n",
    "Action: average_dog_weight: Bulldog\n",
    "<PAUSE>\n",
    "----- execution stops here -----\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: A Bulldog weights 51 lbs\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: A bulldog weights 51 lbs\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383697a",
   "metadata": {},
   "source": [
    "## Implementing Helper Functions\n",
    "\n",
    "To empower our agent with practical capabilities, we'll define several helper functions. These functions will serve as the \"actions\" our agent can perform. In this example, we're providing:\n",
    "\n",
    "1. A basic calculator function\n",
    "2. A function to retrieve average dog weights\n",
    "\n",
    "In a more sophisticated application, these functions could cover a diverse range of operations, from web scraping to database queries to API calls. They are the agent's versatile interface with external data sources and systems, offering a wide range of possibilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "def calculate(what):\n",
    "    return eval(what, {\"__builtins__\": {}}, {})\n",
    "\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\":\n",
    "        return \"Scottish Terriers average 20 lbs\"\n",
    "    elif name in \"Border Collie\":\n",
    "        return \"a Border Collies average weight is 37 lbs\"\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return \"a toy poodles average weight is 7 lbs\"\n",
    "    else:\n",
    "        return \"An average dog weights 50 lbs\"\n",
    "\n",
    "\n",
    "known_actions = {\"calculate\": calculate, \"average_dog_weight\": average_dog_weight}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c3246",
   "metadata": {},
   "source": [
    "## Testing the Agent\n",
    "\n",
    "With our agent and its action set defined, we'll conduct an initial test using a straightforward query about a toy poodle's weight.\n",
    "\n",
    "This test will illuminate the agent's information processing flow:\n",
    "\n",
    "1. It will reason about the necessary steps (identifying the need to look up the weight)\n",
    "2. It will execute an action (invoking the `average_dog_weight` function)\n",
    "3. It will process the observation (the returned weight of a toy poodle)\n",
    "4. It will synthesize this information into a coherent response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "result = abot(\"How much does a toy poodle weigh?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result = average_dog_weight(\"Toy Poodle\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "abot = Agent(prompt)\n",
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871f644-b131-4065-b7ce-b82c20a41f11",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "abot(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d8070-3f36-4cf0-a677-508e54359c8f",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Border Collie\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8a6cc-65d4-4ce7-87aa-4e67d7c23d7b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Scottish Terrier\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b5e62-a203-433c-92a0-3783f490cde1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa923c-7e4f-42d1-965f-0f8ccd50fbd7",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "next_prompt = \"Observation: {}\".format(eval(\"37 + 20\"), {\"__builtins__\": {}}, {})\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c6245-2837-4ac5-983b-95f61f3ac10d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b970c97",
   "metadata": {},
   "source": [
    "### A word on stopSequences\n",
    "\n",
    "Try to remove the `stopSequence` parameter from the above agent class.\n",
    "\n",
    "Now think about a few of the questions below before continuing:\n",
    "\n",
    "- How does your agent perform now?\n",
    "- When should you use `stopSequences`, when could they become a burden for your application?\n",
    "- Does the prompt comply with the [prompting standard of Anthropic](https://docs.anthropic.com/en/docs/prompt-engineering)?\n",
    "\n",
    "At the end of the notebook, try to complete the exercise so that the agent follows your instructions without having to use `stopSequences`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46f2ac-f717-4ab9-b548-f34b74071d76",
   "metadata": {},
   "source": [
    "## Implementing the Reasoning Loop\n",
    "\n",
    "To enhance our agent's autonomy, we'll implement an iterative loop that enables it to reason, act, and observe multiple times in pursuit of an answer. This loop will continue until the agent reaches a conclusion or hits a predefined maximum number of iterations.\n",
    "\n",
    "This approach mirrors how a human expert might tackle a complex problem, gathering information and working through multiple steps until arriving at a solution. The loop empowers our agent to handle more intricate queries that demand multiple steps or data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910915-b087-4d35-afff-0ec30a5852f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "action_re = re.compile(\n",
    "    \"^Action: (\\w+): (.*)$\"\n",
    ")  # python regular expression to selection action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb6cc-5129-4a99-bb45-851bc07b5709",
   "metadata": {
    "height": 421
   },
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [action_re.match(a) for a in result.split(\"\\n\") if action_re.match(a)]\n",
    "        if actions:\n",
    "            # There is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d50e0f",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "\n",
    "To conclude, we'll test our fully-implemented agent with a more complex query requiring multiple steps of reasoning and action. We'll task it with calculating the combined weight of two distinct dog breeds.\n",
    "\n",
    "This comprehensive test will showcase the agent's ability to:\n",
    "\n",
    "1. Deconstruct a complex query into manageable sub-tasks\n",
    "2. Retrieve information for multiple breeds\n",
    "3. Perform calculations using the gathered data\n",
    "4. Integrate all of this information into a coherent final response\n",
    "\n",
    "By working through this practical example, you'll gain valuable insights into the construction of AI agents capable of solving multi-step problems. Moreover, you'll see firsthand how Amazon Bedrock and model providers like Anthropic's Claude can be effectively utilized. This knowledge will empower you to develop more flexible and diverse AI applications in your future projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a02b4-96cc-4b01-8792-397a774eb499",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b1e6b",
   "metadata": {},
   "source": [
    "# Exercise - Rewrite the Agent to use Anthropic style prompting!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b86a6-5e20-4252-b1d8-009b8318345a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
